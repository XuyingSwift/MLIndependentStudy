{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90c0d38f-b9f8-441b-901a-2f1da3ee4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a63e550-51d7-4af3-8260-6d47a5441d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.809773</td>\n",
       "      <td>25.168431</td>\n",
       "      <td>-18.354026</td>\n",
       "      <td>-13.612737</td>\n",
       "      <td>-26.288529</td>\n",
       "      <td>5.304547</td>\n",
       "      <td>19.829286</td>\n",
       "      <td>26.805632</td>\n",
       "      <td>-30.343183</td>\n",
       "      <td>-20.082952</td>\n",
       "      <td>21.403924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.405254</td>\n",
       "      <td>7.894409</td>\n",
       "      <td>-27.188741</td>\n",
       "      <td>16.283305</td>\n",
       "      <td>-29.748012</td>\n",
       "      <td>1.006791</td>\n",
       "      <td>-18.400917</td>\n",
       "      <td>1.454824</td>\n",
       "      <td>6.986963</td>\n",
       "      <td>8.408095</td>\n",
       "      <td>21.075111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.324245</td>\n",
       "      <td>24.312616</td>\n",
       "      <td>-13.219045</td>\n",
       "      <td>10.569770</td>\n",
       "      <td>-1.207372</td>\n",
       "      <td>27.741237</td>\n",
       "      <td>27.645784</td>\n",
       "      <td>-2.837093</td>\n",
       "      <td>11.937643</td>\n",
       "      <td>14.460268</td>\n",
       "      <td>21.344547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.572219</td>\n",
       "      <td>31.280122</td>\n",
       "      <td>21.343705</td>\n",
       "      <td>-8.335016</td>\n",
       "      <td>29.910004</td>\n",
       "      <td>27.525442</td>\n",
       "      <td>-17.659962</td>\n",
       "      <td>16.890195</td>\n",
       "      <td>10.853367</td>\n",
       "      <td>-3.716901</td>\n",
       "      <td>21.550162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-23.117079</td>\n",
       "      <td>25.999806</td>\n",
       "      <td>1.717129</td>\n",
       "      <td>-30.424215</td>\n",
       "      <td>30.471974</td>\n",
       "      <td>26.845881</td>\n",
       "      <td>-13.640445</td>\n",
       "      <td>8.750917</td>\n",
       "      <td>26.574302</td>\n",
       "      <td>23.548366</td>\n",
       "      <td>21.720362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1         x2         x3         x4         x5         x6  \\\n",
       "0  -5.809773  25.168431 -18.354026 -13.612737 -26.288529   5.304547   \n",
       "1 -20.405254   7.894409 -27.188741  16.283305 -29.748012   1.006791   \n",
       "2  24.324245  24.312616 -13.219045  10.569770  -1.207372  27.741237   \n",
       "3  19.572219  31.280122  21.343705  -8.335016  29.910004  27.525442   \n",
       "4 -23.117079  25.999806   1.717129 -30.424215  30.471974  26.845881   \n",
       "\n",
       "          x7         x8         x9        x10     target  \n",
       "0  19.829286  26.805632 -30.343183 -20.082952  21.403924  \n",
       "1 -18.400917   1.454824   6.986963   8.408095  21.075111  \n",
       "2  27.645784  -2.837093  11.937643  14.460268  21.344547  \n",
       "3 -17.659962  16.890195  10.853367  -3.716901  21.550162  \n",
       "4 -13.640445   8.750917  26.574302  23.548366  21.720362  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ackley.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d257c621-d52c-408a-9020-ee6311eb5516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.097740</td>\n",
       "      <td>0.087019</td>\n",
       "      <td>0.039849</td>\n",
       "      <td>-0.150259</td>\n",
       "      <td>0.170307</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>-0.033383</td>\n",
       "      <td>-0.031175</td>\n",
       "      <td>-0.295300</td>\n",
       "      <td>21.097617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.406686</td>\n",
       "      <td>18.503033</td>\n",
       "      <td>18.549034</td>\n",
       "      <td>18.601066</td>\n",
       "      <td>18.411179</td>\n",
       "      <td>18.552889</td>\n",
       "      <td>18.513458</td>\n",
       "      <td>18.501518</td>\n",
       "      <td>18.562738</td>\n",
       "      <td>18.529469</td>\n",
       "      <td>0.428040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-31.982935</td>\n",
       "      <td>-31.996448</td>\n",
       "      <td>-31.997701</td>\n",
       "      <td>-31.998780</td>\n",
       "      <td>-31.999805</td>\n",
       "      <td>-31.990230</td>\n",
       "      <td>-31.997495</td>\n",
       "      <td>-31.992971</td>\n",
       "      <td>-31.999592</td>\n",
       "      <td>-31.998929</td>\n",
       "      <td>17.302517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-15.953672</td>\n",
       "      <td>-15.948880</td>\n",
       "      <td>-16.240481</td>\n",
       "      <td>-16.694236</td>\n",
       "      <td>-15.741310</td>\n",
       "      <td>-16.006710</td>\n",
       "      <td>-16.145195</td>\n",
       "      <td>-15.948280</td>\n",
       "      <td>-16.104392</td>\n",
       "      <td>-16.205878</td>\n",
       "      <td>20.887439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.126936</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.044752</td>\n",
       "      <td>-0.182541</td>\n",
       "      <td>0.184243</td>\n",
       "      <td>-0.365499</td>\n",
       "      <td>0.477923</td>\n",
       "      <td>-0.196748</td>\n",
       "      <td>-0.256268</td>\n",
       "      <td>-0.298176</td>\n",
       "      <td>21.159950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.119616</td>\n",
       "      <td>16.026557</td>\n",
       "      <td>16.204796</td>\n",
       "      <td>15.965724</td>\n",
       "      <td>16.047624</td>\n",
       "      <td>16.122016</td>\n",
       "      <td>16.363389</td>\n",
       "      <td>16.121237</td>\n",
       "      <td>16.209138</td>\n",
       "      <td>15.723710</td>\n",
       "      <td>21.387934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.998509</td>\n",
       "      <td>31.990013</td>\n",
       "      <td>31.993752</td>\n",
       "      <td>31.997751</td>\n",
       "      <td>31.998163</td>\n",
       "      <td>31.999150</td>\n",
       "      <td>31.986743</td>\n",
       "      <td>31.990696</td>\n",
       "      <td>31.987639</td>\n",
       "      <td>31.986088</td>\n",
       "      <td>22.024739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.097740      0.087019      0.039849     -0.150259      0.170307   \n",
       "std       18.406686     18.503033     18.549034     18.601066     18.411179   \n",
       "min      -31.982935    -31.996448    -31.997701    -31.998780    -31.999805   \n",
       "25%      -15.953672    -15.948880    -16.240481    -16.694236    -15.741310   \n",
       "50%       -0.126936      0.074381      0.044752     -0.182541      0.184243   \n",
       "75%       16.119616     16.026557     16.204796     15.965724     16.047624   \n",
       "max       31.998509     31.990013     31.993752     31.997751     31.998163   \n",
       "\n",
       "                 x6            x7            x8            x9           x10  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.025833      0.251800     -0.033383     -0.031175     -0.295300   \n",
       "std       18.552889     18.513458     18.501518     18.562738     18.529469   \n",
       "min      -31.990230    -31.997495    -31.992971    -31.999592    -31.998929   \n",
       "25%      -16.006710    -16.145195    -15.948280    -16.104392    -16.205878   \n",
       "50%       -0.365499      0.477923     -0.196748     -0.256268     -0.298176   \n",
       "75%       16.122016     16.363389     16.121237     16.209138     15.723710   \n",
       "max       31.999150     31.986743     31.990696     31.987639     31.986088   \n",
       "\n",
       "             target  \n",
       "count  10000.000000  \n",
       "mean      21.097617  \n",
       "std        0.428040  \n",
       "min       17.302517  \n",
       "25%       20.887439  \n",
       "50%       21.159950  \n",
       "75%       21.387934  \n",
       "max       22.024739  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics of the dataset\n",
    "descriptive_stats = df.describe()\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b2e8c0a-2b56-45f4-8b7a-1ff9cb2ad6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "224fd680-f355-4b0b-8ab1-1076b624a757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 1.2029 - val_loss: 1.1851\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1483 - val_loss: 1.1305\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0971 - val_loss: 1.0798\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0499 - val_loss: 1.0338\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0076 - val_loss: 0.9931\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9706 - val_loss: 0.9579\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9280\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 0.9022\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8876 - val_loss: 0.8801\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8671 - val_loss: 0.8610\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8492 - val_loss: 0.8441\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8333 - val_loss: 0.8292\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8191 - val_loss: 0.8157\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8063 - val_loss: 0.8036\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7947 - val_loss: 0.7925\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7841 - val_loss: 0.7823\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7743 - val_loss: 0.7730\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7653 - val_loss: 0.7645\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7571 - val_loss: 0.7566\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7494 - val_loss: 0.7493\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7423 - val_loss: 0.7425\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7357 - val_loss: 0.7362\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7296 - val_loss: 0.7304\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7240 - val_loss: 0.7250\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7186 - val_loss: 0.7199\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7136 - val_loss: 0.7150\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7089 - val_loss: 0.7105\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7044 - val_loss: 0.7061\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7001 - val_loss: 0.7019\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6959 - val_loss: 0.6978\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6919 - val_loss: 0.6939\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6880 - val_loss: 0.6900\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6842 - val_loss: 0.6863\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6805 - val_loss: 0.6827\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6770 - val_loss: 0.6792\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6736 - val_loss: 0.6758\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6703 - val_loss: 0.6726\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6672 - val_loss: 0.6697\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6643 - val_loss: 0.6669\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6616 - val_loss: 0.6643\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6591 - val_loss: 0.6621\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6569 - val_loss: 0.6599\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6548 - val_loss: 0.6580\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6530 - val_loss: 0.6562\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6512 - val_loss: 0.6546\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 0.6530\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6481 - val_loss: 0.6516\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6466 - val_loss: 0.6502\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 0.6489\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6440 - val_loss: 0.6477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15b6103d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features in the input\n",
    "input_dim = 11\n",
    "# Set the dimensionality of the encoded (hidden) representation\n",
    "encoded_dim = 10  # Changing this to 10 for 10 hidden nodes\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Define the encoded (hidden) layer\n",
    "encoded = Dense(encoded_dim, activation='relu', activity_regularizer=l1(1e-5))(input_layer)\n",
    "\n",
    "# Define the decoded layer\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Assuming X_std is your standardized dataset\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_std, X_std, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805f9f3-3cd8-4d70-8369-51ba4b4637b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate model for the encoded (hidden) layer to access the reduced dimensions\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# To get the encoded (reduced dimension) output for a given input data (e.g., X_std)\n",
    "encoded_output = encoder.predict(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490bad9-9cde-4e25-ba87-c4b6e3a775e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the encoded output\n",
    "print(\"Shape of encoded output:\", encoded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ac94a-245b-46c7-bc6a-233111d21fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, print only the first few rows of the encoded output\n",
    "print(\"First few rows of Encoded Output:\")\n",
    "print(encoded_output[:])  # Adjust the number as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa397d0-1ad5-48f8-aee0-050c1dbd60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming encoded_output is your array from the encoder model\n",
    "feature_indices = np.argmax(encoded_output, axis=1)\n",
    "print(feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b079bd-4b0b-4fab-b27f-38463b48fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "thresholded_output = np.where(encoded_output > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01191689-1eda-48c2-b4ab-f08e18c5ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thresholded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304cd59-3ab0-4f66-926c-3c75e997aa07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
