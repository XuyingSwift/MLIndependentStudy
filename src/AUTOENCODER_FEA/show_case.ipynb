{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90c0d38f-b9f8-441b-901a-2f1da3ee4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a63e550-51d7-4af3-8260-6d47a5441d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.809773</td>\n",
       "      <td>25.168431</td>\n",
       "      <td>-18.354026</td>\n",
       "      <td>-13.612737</td>\n",
       "      <td>-26.288529</td>\n",
       "      <td>5.304547</td>\n",
       "      <td>19.829286</td>\n",
       "      <td>26.805632</td>\n",
       "      <td>-30.343183</td>\n",
       "      <td>-20.082952</td>\n",
       "      <td>21.403924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.405254</td>\n",
       "      <td>7.894409</td>\n",
       "      <td>-27.188741</td>\n",
       "      <td>16.283305</td>\n",
       "      <td>-29.748012</td>\n",
       "      <td>1.006791</td>\n",
       "      <td>-18.400917</td>\n",
       "      <td>1.454824</td>\n",
       "      <td>6.986963</td>\n",
       "      <td>8.408095</td>\n",
       "      <td>21.075111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.324245</td>\n",
       "      <td>24.312616</td>\n",
       "      <td>-13.219045</td>\n",
       "      <td>10.569770</td>\n",
       "      <td>-1.207372</td>\n",
       "      <td>27.741237</td>\n",
       "      <td>27.645784</td>\n",
       "      <td>-2.837093</td>\n",
       "      <td>11.937643</td>\n",
       "      <td>14.460268</td>\n",
       "      <td>21.344547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.572219</td>\n",
       "      <td>31.280122</td>\n",
       "      <td>21.343705</td>\n",
       "      <td>-8.335016</td>\n",
       "      <td>29.910004</td>\n",
       "      <td>27.525442</td>\n",
       "      <td>-17.659962</td>\n",
       "      <td>16.890195</td>\n",
       "      <td>10.853367</td>\n",
       "      <td>-3.716901</td>\n",
       "      <td>21.550162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-23.117079</td>\n",
       "      <td>25.999806</td>\n",
       "      <td>1.717129</td>\n",
       "      <td>-30.424215</td>\n",
       "      <td>30.471974</td>\n",
       "      <td>26.845881</td>\n",
       "      <td>-13.640445</td>\n",
       "      <td>8.750917</td>\n",
       "      <td>26.574302</td>\n",
       "      <td>23.548366</td>\n",
       "      <td>21.720362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1         x2         x3         x4         x5         x6  \\\n",
       "0  -5.809773  25.168431 -18.354026 -13.612737 -26.288529   5.304547   \n",
       "1 -20.405254   7.894409 -27.188741  16.283305 -29.748012   1.006791   \n",
       "2  24.324245  24.312616 -13.219045  10.569770  -1.207372  27.741237   \n",
       "3  19.572219  31.280122  21.343705  -8.335016  29.910004  27.525442   \n",
       "4 -23.117079  25.999806   1.717129 -30.424215  30.471974  26.845881   \n",
       "\n",
       "          x7         x8         x9        x10     target  \n",
       "0  19.829286  26.805632 -30.343183 -20.082952  21.403924  \n",
       "1 -18.400917   1.454824   6.986963   8.408095  21.075111  \n",
       "2  27.645784  -2.837093  11.937643  14.460268  21.344547  \n",
       "3 -17.659962  16.890195  10.853367  -3.716901  21.550162  \n",
       "4 -13.640445   8.750917  26.574302  23.548366  21.720362  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ackley.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d257c621-d52c-408a-9020-ee6311eb5516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.097740</td>\n",
       "      <td>0.087019</td>\n",
       "      <td>0.039849</td>\n",
       "      <td>-0.150259</td>\n",
       "      <td>0.170307</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>-0.033383</td>\n",
       "      <td>-0.031175</td>\n",
       "      <td>-0.295300</td>\n",
       "      <td>21.097617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.406686</td>\n",
       "      <td>18.503033</td>\n",
       "      <td>18.549034</td>\n",
       "      <td>18.601066</td>\n",
       "      <td>18.411179</td>\n",
       "      <td>18.552889</td>\n",
       "      <td>18.513458</td>\n",
       "      <td>18.501518</td>\n",
       "      <td>18.562738</td>\n",
       "      <td>18.529469</td>\n",
       "      <td>0.428040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-31.982935</td>\n",
       "      <td>-31.996448</td>\n",
       "      <td>-31.997701</td>\n",
       "      <td>-31.998780</td>\n",
       "      <td>-31.999805</td>\n",
       "      <td>-31.990230</td>\n",
       "      <td>-31.997495</td>\n",
       "      <td>-31.992971</td>\n",
       "      <td>-31.999592</td>\n",
       "      <td>-31.998929</td>\n",
       "      <td>17.302517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-15.953672</td>\n",
       "      <td>-15.948880</td>\n",
       "      <td>-16.240481</td>\n",
       "      <td>-16.694236</td>\n",
       "      <td>-15.741310</td>\n",
       "      <td>-16.006710</td>\n",
       "      <td>-16.145195</td>\n",
       "      <td>-15.948280</td>\n",
       "      <td>-16.104392</td>\n",
       "      <td>-16.205878</td>\n",
       "      <td>20.887439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.126936</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.044752</td>\n",
       "      <td>-0.182541</td>\n",
       "      <td>0.184243</td>\n",
       "      <td>-0.365499</td>\n",
       "      <td>0.477923</td>\n",
       "      <td>-0.196748</td>\n",
       "      <td>-0.256268</td>\n",
       "      <td>-0.298176</td>\n",
       "      <td>21.159950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.119616</td>\n",
       "      <td>16.026557</td>\n",
       "      <td>16.204796</td>\n",
       "      <td>15.965724</td>\n",
       "      <td>16.047624</td>\n",
       "      <td>16.122016</td>\n",
       "      <td>16.363389</td>\n",
       "      <td>16.121237</td>\n",
       "      <td>16.209138</td>\n",
       "      <td>15.723710</td>\n",
       "      <td>21.387934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.998509</td>\n",
       "      <td>31.990013</td>\n",
       "      <td>31.993752</td>\n",
       "      <td>31.997751</td>\n",
       "      <td>31.998163</td>\n",
       "      <td>31.999150</td>\n",
       "      <td>31.986743</td>\n",
       "      <td>31.990696</td>\n",
       "      <td>31.987639</td>\n",
       "      <td>31.986088</td>\n",
       "      <td>22.024739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.097740      0.087019      0.039849     -0.150259      0.170307   \n",
       "std       18.406686     18.503033     18.549034     18.601066     18.411179   \n",
       "min      -31.982935    -31.996448    -31.997701    -31.998780    -31.999805   \n",
       "25%      -15.953672    -15.948880    -16.240481    -16.694236    -15.741310   \n",
       "50%       -0.126936      0.074381      0.044752     -0.182541      0.184243   \n",
       "75%       16.119616     16.026557     16.204796     15.965724     16.047624   \n",
       "max       31.998509     31.990013     31.993752     31.997751     31.998163   \n",
       "\n",
       "                 x6            x7            x8            x9           x10  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.025833      0.251800     -0.033383     -0.031175     -0.295300   \n",
       "std       18.552889     18.513458     18.501518     18.562738     18.529469   \n",
       "min      -31.990230    -31.997495    -31.992971    -31.999592    -31.998929   \n",
       "25%      -16.006710    -16.145195    -15.948280    -16.104392    -16.205878   \n",
       "50%       -0.365499      0.477923     -0.196748     -0.256268     -0.298176   \n",
       "75%       16.122016     16.363389     16.121237     16.209138     15.723710   \n",
       "max       31.999150     31.986743     31.990696     31.987639     31.986088   \n",
       "\n",
       "             target  \n",
       "count  10000.000000  \n",
       "mean      21.097617  \n",
       "std        0.428040  \n",
       "min       17.302517  \n",
       "25%       20.887439  \n",
       "50%       21.159950  \n",
       "75%       21.387934  \n",
       "max       22.024739  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics of the dataset\n",
    "descriptive_stats = df.describe()\n",
    "descriptive_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b2e8c0a-2b56-45f4-8b7a-1ff9cb2ad6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "224fd680-f355-4b0b-8ab1-1076b624a757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 1.2512 - val_loss: 1.2285\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1951 - val_loss: 1.1743\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1436 - val_loss: 1.1235\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0947 - val_loss: 1.0753\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0485 - val_loss: 1.0304\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0062 - val_loss: 0.9902\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 0.9551\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9363 - val_loss: 0.9252\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9087 - val_loss: 0.8999\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8853 - val_loss: 0.8784\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8651 - val_loss: 0.8597\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8474 - val_loss: 0.8432\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8317 - val_loss: 0.8284\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8176 - val_loss: 0.8150\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8048 - val_loss: 0.8029\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7931 - val_loss: 0.7917\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7822 - val_loss: 0.7815\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7723 - val_loss: 0.7721\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7631 - val_loss: 0.7633\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7545 - val_loss: 0.7552\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7466 - val_loss: 0.7477\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7393 - val_loss: 0.7407\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7324 - val_loss: 0.7342\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7259 - val_loss: 0.7280\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7199 - val_loss: 0.7222\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7142 - val_loss: 0.7168\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7089 - val_loss: 0.7117\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7039 - val_loss: 0.7068\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6991 - val_loss: 0.7023\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - val_loss: 0.6979\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6904 - val_loss: 0.6938\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6863 - val_loss: 0.6899\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6825 - val_loss: 0.6862\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6788 - val_loss: 0.6826\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6753 - val_loss: 0.6792\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6719 - val_loss: 0.6760\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6688 - val_loss: 0.6729\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6658 - val_loss: 0.6700\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6630 - val_loss: 0.6673\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6604 - val_loss: 0.6648\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6579 - val_loss: 0.6624\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6556 - val_loss: 0.6601\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6534 - val_loss: 0.6580\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6513 - val_loss: 0.6560\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6494 - val_loss: 0.6541\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6476 - val_loss: 0.6523\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6459 - val_loss: 0.6507\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6442 - val_loss: 0.6490\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6427 - val_loss: 0.6475\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x150609ed0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features in the input\n",
    "input_dim = 11\n",
    "# Set the dimensionality of the encoded (hidden) representation\n",
    "encoded_dim = 10  # Changing this to 10 for 10 hidden nodes\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Define the encoded (hidden) layer\n",
    "encoded = Dense(encoded_dim, activation='relu', activity_regularizer=l1(1e-5))(input_layer)\n",
    "\n",
    "# Define the decoded layer\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Assuming X_std is your standardized dataset\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_std, X_std, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9805f9f3-3cd8-4d70-8369-51ba4b4637b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 658us/step\n"
     ]
    }
   ],
   "source": [
    "# Create a separate model for the encoded (hidden) layer to access the reduced dimensions\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# To get the encoded (reduced dimension) output for a given input data (e.g., X_std)\n",
    "encoded_output = encoder.predict(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9490bad9-9cde-4e25-ba87-c4b6e3a775e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded output: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the encoded output\n",
    "print(\"Shape of encoded output:\", encoded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a0ac94a-245b-46c7-bc6a-233111d21fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of Encoded Output:\n",
      "[[3.6360233  0.         0.41626978 ... 4.3395963  0.         3.416203  ]\n",
      " [1.659308   1.7155526  2.242031   ... 1.1393654  0.4458226  2.9344146 ]\n",
      " [0.         0.         0.7060803  ... 1.7897782  0.         1.841846  ]\n",
      " ...\n",
      " [1.5199821  0.         0.         ... 2.1403928  1.4417713  1.3573983 ]\n",
      " [2.4249969  0.         0.28744304 ... 0.         2.5644107  1.000809  ]\n",
      " [0.36023986 2.723522   3.2055786  ... 0.5813017  3.075306   2.5387151 ]]\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, print only the first few rows of the encoded output\n",
    "print(\"First few rows of Encoded Output:\")\n",
    "print(encoded_output[:])  # Adjust the number as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfa397d0-1ad5-48f8-aee0-050c1dbd60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 9 ... 7 6 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming encoded_output is your array from the encoder model\n",
    "feature_indices = np.argmax(encoded_output, axis=1)\n",
    "print(feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85b079bd-4b0b-4fab-b27f-38463b48fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "thresholded_output = np.where(encoded_output > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01191689-1eda-48c2-b4ab-f08e18c5ac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(thresholded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8304cd59-3ab0-4f66-926c-3c75e997aa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "unique_rows = np.unique(thresholded_output, axis=0)\n",
    "print(len(unique_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "942af67f-6094-4c12-9a45-3be1fd9a3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_rows(unique_rows, overlap_threshold):\n",
    "    n_rows = unique_rows.shape[0]\n",
    "    overlapping_groups = []\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        for j in range(i+1, n_rows):\n",
    "            # Count the number of matching elements\n",
    "            similarity = np.sum(unique_rows[i] == unique_rows[j])\n",
    "            if similarity >= overlap_threshold:\n",
    "                # Convert arrays to tuples for comparison\n",
    "                group = (tuple(unique_rows[i]), tuple(unique_rows[j]))\n",
    "                overlapping_groups.append(group)\n",
    "\n",
    "    # Select unique groups until we have 10 of them\n",
    "    unique_groups = []\n",
    "    for group in overlapping_groups:\n",
    "        if group not in unique_groups:\n",
    "            unique_groups.append(group)\n",
    "            if len(unique_groups) == 10:\n",
    "                break\n",
    "\n",
    "    return unique_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5565ac3-3275-4e1c-8375-a34336788bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 1)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 1, 0)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 1, 0, 1)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 1, 1, 1, 1)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 0, 0, 0, 0)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 0, 1, 0, 1)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 0, 1, 1, 0)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 0, 1, 1, 1)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 1, 0, 1, 0)), ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 1, 1, 0, 1, 1))]\n"
     ]
    }
   ],
   "source": [
    "overlap_threshold = 3  # Define how many elements need to match for rows to be considered overlapping\n",
    "overlapping_rows = find_overlapping_rows(unique_rows, overlap_threshold)\n",
    "print(overlapping_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1cdf0-04e7-43eb-8616-eb4528c2bcae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0af7a-da5d-4ea6-970c-24608a9e4de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
